# Velocity Tracking Sheet

**Purpose**: Track your story point completion across sprints to build predictable capacity planning and improve estimation accuracy.
**When to Use**: Update at the end of each sprint during retrospective
**Time to Complete**: 10 minutes per sprint

---

## Instructions

1. **Record sprint data** - Log planned vs completed story points
2. **Calculate velocity** - Velocity = story points completed (not planned)
3. **Track trends** - Look for patterns across 3+ sprints
4. **Analyze variance** - Understand what causes velocity to fluctuate
5. **Predict capacity** - Use average velocity to plan next sprint
6. **Document factors** - Note what affected velocity (exams, learning, blockers)

Velocity is your most important planning metric. It's not about being fast - it's about being predictable.

---

## Template

### Velocity Tracking - CSC-114

**Student**: [Your Name]
**Semester**: [Term/Year]

---

### Sprint-by-Sprint Velocity

| Sprint # | Dates | Days | Planned Points | Completed Points | Velocity | % Complete | Notes |
|----------|-------|------|----------------|------------------|----------|------------|-------|
| 1 | | | | | | | |
| 2 | | | | | | | |
| 3 | | | | | | | |
| 4 | | | | | | | |
| 5 | | | | | | | |
| 6 | | | | | | | |
| 7 | | | | | | | |
| 8 | | | | | | | |

**Average Velocity (all sprints)**: ___ points
**Average Velocity (last 3 sprints)**: ___ points
**Most Common Velocity**: ___ points

---

### Velocity Trend Analysis

**Visual Trend:**
```
Points
15 |
14 |
13 |              ●
12 |        ●           ●
11 |                         ●
10 |   ●                           ●
9  |                                    ●
8  |        ●
   +-----------------------------------------> Sprint #
    1   2   3   4   5   6   7   8
```

**Trend Pattern:**
- [ ] Increasing (getting faster or better at estimation)
- [ ] Stable (consistent, predictable)
- [ ] Decreasing (slower or more complex work)
- [ ] Volatile (inconsistent, unpredictable)

**What explains this trend?**


---

### Capacity Planning for Next Sprint

**Next Sprint (#___)**: [Dates]

**Available Hours**:
- Total days in sprint: ___
- Hours available per day: ___
- Total available hours: ___

**Capacity Adjustments:**
- [ ] Exams or major deadlines? (Reduce capacity by 30-50%)
- [ ] New technology to learn? (Add learning buffer)
- [ ] Holidays or time off? (Reduce available days)
- [ ] Carry-over incomplete work? (Reduce new work capacity)

**Predicted Velocity**: ___ points (based on: [average/recent trend/adjusted])

**Confidence Level**:
- [ ] High (stable velocity, no major changes)
- [ ] Medium (some uncertainty)
- [ ] Low (new sprint conditions, volatility)

**Planned Commitment**: ___ points

---

### Estimation Accuracy Analysis

| Sprint # | Story ID | Estimated Points | Actual Difficulty | Variance | Reason for Variance |
|----------|----------|------------------|-------------------|----------|---------------------|
| | | | [ ] Easier [ ] Accurate [ ] Harder | | |
| | | | [ ] Easier [ ] Accurate [ ] Harder | | |
| | | | [ ] Easier [ ] Accurate [ ] Harder | | |

**Patterns in Estimation Errors:**
- Stories consistently underestimated: [Type of work]
- Stories consistently overestimated: [Type of work]
- Estimation blind spots: [What I don't account for]

**Estimation Improvements for Next Sprint:**
-
-

---

### Velocity Factors Log

**What increases my velocity?**
- [ ] Familiar technology (no learning curve)
- [ ] Well-defined stories (clear requirements)
- [ ] Uninterrupted time (no exams or distractions)
- [ ] Good rest and focus
- [ ] Other: ___________

**What decreases my velocity?**
- [ ] Learning new tech
- [ ] Vague or complex requirements
- [ ] External time pressure (exams, other courses)
- [ ] Technical blockers
- [ ] Other: ___________

**Personal Velocity Insights:**
[Notes about your work patterns, peak productivity times, etc.]


---

### Points Per Hour Analysis

| Sprint # | Completed Points | Hours Worked | Points per Hour | Efficiency Notes |
|----------|------------------|--------------|-----------------|------------------|
| 1 | | | | |
| 2 | | | | |
| 3 | | | | |

**Average Points per Hour**: ___

**Efficiency Trends:**
- Am I getting more efficient over time?
- What work gives best points-per-hour ratio?
- What work is time-intensive relative to points?

---

### Velocity Goals

**Short-term goal (next 2 sprints):**
- Target: Achieve consistent velocity within +/- 2 points
- Why: [Improve predictability for project planning]

**Long-term goal (semester):**
- Target: ___
- Why: ___

**How I'll achieve these goals:**
-
-

---

## Example (Filled)

### Velocity Tracking - CSC-114

**Student**: Alex Chen
**Semester**: Spring 2026

---

### Sprint-by-Sprint Velocity

| Sprint # | Dates | Days | Planned Points | Completed Points | Velocity | % Complete | Notes |
|----------|-------|------|----------------|------------------|----------|------------|-------|
| 1 | Jan 20-Feb 2 | 14 | 12 | 10 | 10 | 83% | First sprint, learning curve |
| 2 | Feb 3-16 | 14 | 13 | 13 | 13 | 100% | Solid sprint, no blockers |
| 3 | Feb 17-Mar 2 | 14 | 11 | 8 | 8 | 73% | Midterm impact, CNN tuning hard |
| 4 | Mar 3-16 | 14 | 10 | 12 | 12 | 120% | Overdelivered, good momentum |
| 5 | Mar 17-30 | 14 | 12 | 11 | 11 | 92% | Spring break, less time |
| 6 | Mar 31-Apr 13 | 14 | 11 | 11 | 11 | 100% | Consistent, hitting stride |
| 7 | Apr 14-27 | 14 | 11 | 9 | 9 | 82% | Final exams prep started |
| 8 | Apr 28-May 11 | 14 | 10 | 10 | 10 | 100% | Final project push |

**Average Velocity (all sprints)**: 10.5 points
**Average Velocity (last 3 sprints)**: 10 points
**Most Common Velocity**: 10-11 points

---

### Velocity Trend Analysis

**Visual Trend:**
```
Points
15 |
14 |
13 |        ●
12 |              ●
11 |                    ●     ●
10 |   ●                           ●     ●
9  |                                   ●
8  |              ●
   +-----------------------------------------> Sprint #
    1   2   3   4   5   6   7   8
```

**Trend Pattern:**
- [ ] Increasing
- [x] Stable (consistent, predictable)
- [ ] Decreasing
- [ ] Volatile

**What explains this trend?**
After volatile start (sprints 1-4: 10, 13, 8, 12), velocity stabilized in sprints 5-8 (11, 11, 9, 10). This shows improving estimation accuracy and better understanding of my capacity. The dip in sprint 3 (midterm) and sprint 7 (finals prep) shows external factors impact velocity predictably.

---

### Capacity Planning for Next Sprint

**Next Sprint (#9)**: May 12-25

**Available Hours**:
- Total days in sprint: 14
- Hours available per day: 2
- Total available hours: 28

**Capacity Adjustments:**
- [ ] Exams or major deadlines? (Finals are over)
- [ ] New technology to learn? (No, sticking with Keras/TensorFlow)
- [ ] Holidays or time off? (No)
- [x] Carry-over incomplete work? (2 points from Sprint 8, reduce new work)

**Predicted Velocity**: 10 points (based on: last 3 sprint average)

**Confidence Level**:
- [x] High (stable velocity, no major changes)
- [ ] Medium
- [ ] Low

**Planned Commitment**: 8 points (10 predicted - 2 carry-over = 8 new)

---

### Estimation Accuracy Analysis

| Sprint # | Story ID | Estimated Points | Actual Difficulty | Variance | Reason for Variance |
|----------|----------|------------------|-------------------|----------|---------------------|
| 3 | US-009 | 3 | [x] Harder | +2 | Hyperparameter tuning took longer than expected, learning curve |
| 4 | US-012 | 5 | [ x] Easier | -2 | Transfer learning was simpler than anticipated, good docs |
| 5 | US-015 | 3 | [x] Accurate | 0 | Nailed it - data augmentation well-scoped |
| 6 | US-018 | 5 | [x] Accurate | 0 | Model deployment story correctly estimated |
| 7 | US-021 | 3 | [x] Harder | +1 | API integration had unexpected auth issues |

**Patterns in Estimation Errors:**
- Stories consistently underestimated: Hyperparameter tuning, API integrations (external dependencies)
- Stories consistently overestimated: Data preprocessing, model building (getting better at these)
- Estimation blind spots: Learning time for new techniques, debugging time

**Estimation Improvements for Next Sprint:**
- Add +1 point buffer for any story involving external APIs or services
- Add "research spike" story (2 points) when learning completely new technique
- Trust my estimates for data engineering work - I'm good at this now

---

### Velocity Factors Log

**What increases my velocity?**
- [x] Familiar technology (Keras is second nature now)
- [x] Well-defined stories (clear acceptance criteria speeds me up)
- [x] Uninterrupted time (2-hour morning blocks are my peak)
- [x] Good rest and focus (8 hours sleep = much better code)
- [x] Other: Pair programming with classmates - learn faster

**What decreases my velocity?**
- [x] Learning new tech (deployment tools took 2 days to learn)
- [x] Vague or complex requirements (spent day clarifying before coding)
- [x] External time pressure (exams kill my focus for 3-4 days)
- [x] Technical blockers (GPU availability issues wasted time)
- [ ] Other: ___________

**Personal Velocity Insights:**
I work best in 2-3 hour morning sessions (8am-11am). Evening coding is half as efficient. I'm naturally better at data engineering than model tuning - should budget more time for tuning work. Exams impact me more than I think they will - need to reduce capacity by 40-50%, not 30%.

---

### Points Per Hour Analysis

| Sprint # | Completed Points | Hours Worked | Points per Hour | Efficiency Notes |
|----------|------------------|--------------|-----------------|------------------|
| 1 | 10 | 24 | 0.42 | Lots of environment setup, learning |
| 2 | 13 | 26 | 0.50 | Hit flow state, minimal blockers |
| 3 | 8 | 22 | 0.36 | Midterm disruption, low focus |
| 4 | 12 | 20 | 0.60 | Most efficient sprint - familiar work |
| 5 | 11 | 24 | 0.46 | Consistent productivity |
| 6 | 11 | 23 | 0.48 | Steady pace maintained |
| 7 | 9 | 26 | 0.35 | Finals prep, distracted |
| 8 | 10 | 22 | 0.45 | Back to baseline efficiency |

**Average Points per Hour**: 0.45

**Efficiency Trends:**
- Peak efficiency: Sprint 4 (0.60 pts/hr) - familiar tech, clear stories, uninterrupted time
- Lowest efficiency: Sprint 3 & 7 (0.35-0.36) - exam periods
- Stable efficiency: Sprints 5, 6, 8 (~0.45-0.48) - this is my baseline when focused

**Insights:**
- Data preprocessing and model building: ~0.5-0.6 pts/hr (efficient)
- Hyperparameter tuning and debugging: ~0.3-0.4 pts/hr (time-intensive)
- Learning new tech: ~0.3 pts/hr (plan accordingly)

---

### Velocity Goals

**Short-term goal (next 2 sprints):**
- Target: Achieve velocity of 10 +/- 1 point in both sprints
- Why: Demonstrate predictable capacity for final project planning. Stable velocity = professional estimation skills.

**Long-term goal (semester):**
- Target: Complete final project with 3 weeks buffer before deadline
- Why: Using predictable velocity (10 pts/sprint) to scope final project at 40 points over 4 sprints, leaving 3 weeks for polish and unexpected issues.

**How I'll achieve these goals:**
- Continue daily standups and burndown tracking
- Use 10 points as baseline, adjust for known factors (exams, learning)
- Front-load sprints - aim for 50% completion by midpoint
- Don't overcommit trying to "beat" previous velocity
- Log actual hours worked to improve points-per-hour estimates

---

## Why This Matters

Velocity tracking is the foundation of predictable delivery in software engineering.

When I worked at Spotify, we tracked team velocity religiously. Why? Because stakeholders ask: "When will this feature ship?"

Without velocity data, you're guessing. With velocity data, you're forecasting.

Here's what velocity gives you:
1. **Predictable planning** - "I complete 10 points per sprint, this feature is 25 points, so it takes 2.5 sprints"
2. **Realistic commitments** - No more "I'll work harder" - you know your actual capacity
3. **Scope management** - "I have 4 sprints left and 50 points of work - something's gotta give"
4. **Estimation improvement** - Track what you underestimate, adjust future estimates

The ML engineers who advance fastest are the ones who can say: "This model will take 6 weeks" and then deliver in 6 weeks. That requires knowing your velocity.

**Velocity isn't about being fast. It's about being predictable.**

---

## Common Mistakes to Avoid

- **Mistake**: Trying to increase velocity every sprint ("I'll just work harder")
  **Better approach**: Velocity is a measurement, not a goal. Focus on predictability, not speed. A stable 8 points is better than volatile 5, 15, 6, 12.

- **Mistake**: Comparing your velocity to other students
  **Better approach**: Velocity is personal. Some students have 15 points/sprint, some have 8. Both are fine. What matters: Are YOU predictable?

- **Mistake**: Ignoring factors that affect velocity (exams, learning, life)
  **Better approach**: Log everything that impacts velocity. Patterns emerge. "I always drop 30% during exams" becomes data you plan for.

- **Mistake**: Using only recent velocity, ignoring trends
  **Better approach**: Look at last 3 sprints for average, but also consider trend. If velocity is dropping (12, 10, 8), investigate why before planning.

- **Mistake**: Not tracking WHY velocity changed
  **Better approach**: The "Notes" column is critical. "Velocity dropped because I learned new tech" is actionable. "Velocity dropped" isn't.

---

## Tips from Drew

**Your velocity will stabilize after 3-4 sprints.** Early sprints are noisy - you're learning the codebase, the tools, your capacity. By sprint 4, you'll have a reliable baseline. Don't stress about early volatility.

**Use average of last 3 sprints for planning.** Not all-time average (too much old data), not just last sprint (could be an outlier). Last 3 is the sweet spot.

**Velocity dropping isn't necessarily bad.** Maybe you're working on harder problems. Maybe you're learning new tech. Context matters. What's bad is velocity dropping and not knowing why.

**Track "points per hour" to separate time from efficiency.** If your velocity drops but your points-per-hour is stable, you just had less time. If points-per-hour drops, something's affecting your efficiency (blockers, focus, complexity).

**Stable velocity is more valuable than high velocity.** I'd rather work with someone who consistently delivers 8 points than someone who does 15, then 5, then 12, then 6. Predictability enables planning.

**Your velocity is YOUR velocity.** Some students are taking 18 credits, working part-time, have family obligations. Some are taking 12 credits with no job. Different velocities are expected and fine. What's not fine: not knowing your own velocity.

**The "planned vs completed" gap shows overcommitment patterns.** If you're consistently completing 70% of planned points, you're overcommitting by 30%. Adjust future planning. It's math, not motivation.

---

## Integration with CSC-114

In CSC-114, velocity tracking is essential for final project scoping.

Here's why: Your final project is self-scoped. You decide what to build. How do you know what's realistic in 4 sprints?

**Without velocity data:**
"I'll build a sentiment analysis model with web scraping, real-time inference API, React dashboard, and deploy to AWS."
(Spoiler: That's 60+ story points. You have capacity for 40.)

**With velocity data:**
"My velocity is 10 points/sprint. I have 4 sprints = 40 points capacity. Sentiment model is 15 points, API is 12 points, deployment is 8 points, dashboard is 10 points. That's 45 points. I'll cut the dashboard or reduce its scope."

**This is professional project management.**

I grade your final project partly on realistic scoping. Students with velocity data scope realistically and finish strong. Students without velocity data either:
1. Over-scope and deliver 60% of a too-ambitious project
2. Under-scope and finish with 3 weeks left wondering what to do

**Your velocity tracking sheet is your planning tool for success.**

Track it diligently, learn from it, and use it to make smart scope decisions. This skill will serve you for your entire career.
